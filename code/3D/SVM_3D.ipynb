{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperplane folding.\n",
    "\n",
    "The following code runs the algorithm from the paper:\n",
    "*Hyperplane folding - a way to increase the margin in Support Vector Machines\n",
    "*Lars Lundberg, Håkan Lennerstad, Eva Garcia-Martin, Niklas Lavesson and Veselka Boeva\n",
    "\n",
    "It does the following:\n",
    "1. Apply SVM in a dataset\n",
    "2. Select the primary support vector\n",
    "3. Divide the points into two, ones to the left of the support vector (forming an orthogonal line with the hyperplane) and the other ones to the right of the support vector\n",
    "4. Apply two SVM on each new set of points\n",
    "5. Rotate one side an angle a. \n",
    "6. The margin has thus increased from the initial one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulation functions\n",
    "\"\"\"\n",
    "\n",
    "def generate_point(center, radius):\n",
    "    #Generate a random vector on the unit circle (length 1)\n",
    "    ang = uniform(0, 2*pi)\n",
    "    v = np.array([cos(ang), sin(ang)])\n",
    " \n",
    "    # Generate a normally distributed length\n",
    "    #(mean = 0, so the length can be negative)\n",
    "    l = radius + 1\n",
    "    while abs(l) > radius:\n",
    "        l = normalvariate(0, radius)\n",
    "    return center + l * v\n",
    "\n",
    "\n",
    "def generate_points(centers, points_per_circle, radius):\n",
    "    X = list()\n",
    "    Y = list()\n",
    "    count = 1\n",
    "    \n",
    "    for center in centers:\n",
    "        for i in range(points_per_circle):\n",
    "            X.append(generate_point(center, radius))\n",
    "            if count%2:\n",
    "                Y.append(0)\n",
    "            else:\n",
    "                Y.append(1)\n",
    "        count += 1\n",
    "        \n",
    "    X=np.array(X)\n",
    "    Y=np.array(Y)\n",
    "    return (X,Y)\n",
    "\n",
    "def get_margin(clf):\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    s_vectors = clf.support_vectors_\n",
    "    intrc_up = (s_vectors[-1][1] - a * s_vectors[-1][0])\n",
    "    intrc_down = (s_vectors[0][1] - a * s_vectors[0][0])\n",
    "    margin = (abs(intrc_up - intrc_down))/(math.sqrt(1+(a*a)))\n",
    "    return margin\n",
    "\n",
    "def plot_SVM_backup(clf,X,Y, should_plot):\n",
    "    if should_plot: \n",
    "     \n",
    "        plt.scatter(X[:, 0], X[:, 1], c=Y, s=30, cmap=plt.cm.Paired)\n",
    "\n",
    "        # plot the decision function\n",
    "        ax = plt.gca()\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "\n",
    "        # create grid to evaluate model\n",
    "        xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "#         xx = np.linspace(X[:,0].min(),X[:,0].max())\n",
    "\n",
    "\n",
    "        yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "        # plot decision boundary and margins\n",
    "        ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "                   linestyles=['--', '-', '--'])\n",
    "        # plot support vectors\n",
    "        ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\n",
    "                   linewidth=1, facecolors='none', zorder=10, edgecolors='k')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         w = clf.coef_[0]\n",
    "#         a = -w[0] / w[1]\n",
    "#         xx = np.linspace(X[:,0].min(),X[:,0].max())\n",
    "#         intercept = -(clf.intercept_[0]) / w[1]\n",
    "#         s_vectors = clf.support_vectors_\n",
    "\n",
    "#         # Margin\n",
    "#         intrc_up = (s_vectors[-1][1] - a * s_vectors[-1][0])\n",
    "#         intrc_down = (s_vectors[0][1] - a * s_vectors[0][0])\n",
    "#         yy = a * xx + intercept\n",
    "#         yy_up = a * xx + intrc_up\n",
    "#         yy_down = a * xx + intrc_down\n",
    "        \n",
    "#         plt.plot(xx, yy, 'k-')\n",
    "#         plt.plot(xx, yy_down, 'k--')\n",
    "#         plt.plot(xx, yy_up, 'k--')\n",
    "\n",
    "#         plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],s=80, facecolors='none')\n",
    "#         plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n",
    "#         plt.axis('tight')\n",
    "#         plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "def plot_SVM(clf,X,Y, should_plot):\n",
    "    if should_plot: \n",
    "        w = clf.coef_[0]\n",
    "        a = -w[0] / w[1]\n",
    "        xx = np.linspace(X[:,0].min(),X[:,0].max())\n",
    "        intercept = -(clf.intercept_[0]) / w[1]\n",
    "        s_vectors = clf.support_vectors_\n",
    "\n",
    "        # Margin\n",
    "        intrc_up = (s_vectors[-1][1] - a * s_vectors[-1][0])\n",
    "        intrc_down = (s_vectors[0][1] - a * s_vectors[0][0])\n",
    "        yy = a * xx + intercept\n",
    "        yy_up = a * xx + intrc_up\n",
    "        yy_down = a * xx + intrc_down\n",
    "        \n",
    "        plt.plot(xx, yy, 'k-')\n",
    "        plt.plot(xx, yy_down, 'k--')\n",
    "        plt.plot(xx, yy_up, 'k--')\n",
    "\n",
    "        plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1],s=80, \n",
    "                    facecolors='none',zorder=10, edgecolors='k')\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n",
    "        plt.axis('tight')\n",
    "        plt.show()\n",
    "#         pdf.savefig(fig) # note the format='pdf' argument!\n",
    "#         pdf.close()\n",
    "    \n",
    "def get_support_vector(X, Y, sv_index):\n",
    "    \"\"\"\n",
    "    Return the prime support vector. sv_index: indices of the SVs\n",
    "    We first calculate the sum. If the sum is 1, it means that there are \n",
    "    2 SVs in class 0, and 1 in class 1. Thus we need to choose the SV in class 1\n",
    "    If the sum is 2, then we need to return the X where Y = 0. \n",
    "    \"\"\"\n",
    "    print(\"Function: get support vector. SVs indixes: \", sv_index)\n",
    "    s=0\n",
    "    supp_v=0\n",
    "    for i in sv_index:\n",
    "        s += Y.iloc[i]\n",
    "    for n in sv_index:\n",
    "        if Y.iloc[n] == 1 and s == 1:\n",
    "            return X.iloc[n]\n",
    "        if Y.iloc[n] == 0 and s == 2:\n",
    "            return X.iloc[n]\n",
    "      \n",
    "    raise Exception(\"Error in function get_support_vector. Values: s: \" + str(s) + \" SV index: \" + str(sv_index) )\n",
    "        \n",
    "\n",
    "def point_vs_othline(point, prime_sv,  a): \n",
    "#     print(\"DEBUG point_vs_othline: point: \", point)\n",
    "#     print(\"DEBUG : prime SV \", prime_sv, \"a: \", a )\n",
    "    \n",
    "    t = (point[0] - prime_sv[0])/(-a)\n",
    "    if (point[1]) <= (prime_sv[1] + t):\n",
    "        return \"higher/right\"\n",
    "    else:\n",
    "        return \"lower/left\"\n",
    "    \n",
    "def splitting_backup(X,Y, clf, prime_sv):\n",
    "    r\"\"\"\n",
    "    Splitting the points in X and Y, based on an orthogonal line to the hyperplane\n",
    "    obtained by the classifier clf\n",
    "    \n",
    "    return: both sets of points\n",
    "    \"\"\"\n",
    "    set1x=list()\n",
    "    set2x=list()\n",
    "    set1y=list()\n",
    "    set2y=list()\n",
    "    # In case there are more than 1 point with the same value as the support vector, so that we don't add it twice.\n",
    "    already_added = False\n",
    "    \n",
    "\n",
    "    if len(clf.support_vectors_) == 3: \n",
    "        w = clf.coef_[0]\n",
    "        a = -w[0] / w[1]\n",
    "        i=0\n",
    "        for item in X:\n",
    "            if (item[0]==prime_sv[0]) and (item[1]==prime_sv[1]) and already_added == False:\n",
    "                set1x.append(item)\n",
    "                set1y.append(Y[i])\n",
    "                set2x.append(item)\n",
    "                set2y.append(Y[i])\n",
    "                already_added = True\n",
    "            elif point_vs_othline(item,prime_sv,a ) == \"higher/right\":\n",
    "                set2x.append(item)\n",
    "                set2y.append(Y[i])\n",
    "            elif point_vs_othline(item,prime_sv,a) == \"lower/left\":\n",
    "                set1x.append(item)\n",
    "                set1y.append(Y[i])\n",
    "            else:\n",
    "                print(\"There is something wrong. Point is not either higher nor lower\")\n",
    "            i+=1\n",
    "    else:\n",
    "        raise Exception('More than 3 Support Vectors. N of SV: ', suppsum )\n",
    "    return [set1x, set1y, set2x, set2y]\n",
    "\n",
    "def splitting(X,Y,clf,prime_sv):\n",
    "    r\"\"\"\n",
    "    Splitting the points in X and Y, based on an orthogonal line to the hyperplane\n",
    "    obtained by the classifier clf\n",
    "    \n",
    "    return: both sets of points, as DFs mantaining original index\n",
    "    \"\"\"\n",
    "    index_set1 = list()\n",
    "    index_set2 = list()\n",
    "    already_added = False\n",
    "    prime_sv_index = None\n",
    "\n",
    "    if len(clf.support_vectors_) == 3: \n",
    "        # Indexes\n",
    "        w = clf.coef_[0]\n",
    "        a = -w[0] / w[1]\n",
    "        i=0\n",
    "        print(\"prime_sv \", prime_sv)\n",
    "\n",
    "        for item in np.array(X):\n",
    "            if (item[0]==prime_sv[0]) and (item[1]==prime_sv[1]) and already_added == False:\n",
    "                index_set1.append(i)\n",
    "                index_set2.append(i)\n",
    "                prime_sv_index = i\n",
    "                already_added = True\n",
    "            elif point_vs_othline(item,prime_sv,a ) == \"higher/right\":\n",
    "                index_set2.append(i)\n",
    "            elif point_vs_othline(item,prime_sv,a) == \"lower/left\":\n",
    "                index_set1.append(i)\n",
    "            else:\n",
    "                print(\"Error in Splitting function. Point is not higher nor lower\")\n",
    "            i+=1\n",
    "          \n",
    "        print(\"Indexes: Set1: \", index_set1, \" Set2: \", index_set2)\n",
    "        print(\"prime_sv_index: \", prime_sv_index)\n",
    "\n",
    "        # Get the DFs\n",
    "        set1X = X.iloc[index_set1]\n",
    "        set2X = X.iloc[index_set2]\n",
    "        set1Y = Y.iloc[index_set1]\n",
    "        set2Y = Y.iloc[index_set2]\n",
    "    else:\n",
    "        raise Exception('More than 3 Support Vectors. N of SV: ', suppsum )\n",
    "    return [set1X, set2X, set1Y, set2Y, prime_sv_index]\n",
    "        \n",
    "\n",
    "def get_folding_point(clf1, clf2):\n",
    "    \n",
    "    w1 = clf1.coef_[0]\n",
    "    a1 = -w1[0] / w1[1]\n",
    "    intercept1= -(clf1.intercept_[0]) / w1[1]\n",
    "    \n",
    "    w2 = clf2.coef_[0]\n",
    "    a2 = -w2[0] / w2[1]\n",
    "    intercept2= -(clf2.intercept_[0]) / w2[1]\n",
    "    \n",
    "    xf = (intercept2-intercept1)/(a1-a2)\n",
    "    yf = xf*a1 + intercept1\n",
    "    \n",
    "    angle = np.arctan(a1) - np.arctan(a2)\n",
    "    return [xf,yf] , angle\n",
    "    \n",
    "def remove_supp (sx, sy, supp):\n",
    "    \n",
    "    index=0\n",
    "    while sx[index][0] != supp[0] and sx[index][1] != supp[1]:\n",
    "        index+=1\n",
    "    sx = np.delete(sx,index, 0)\n",
    "    sy = np.delete(sy,index)\n",
    "    \n",
    "    return sx,sy\n",
    "    \n",
    "     \n",
    "\n",
    "def folding_set(X, f_point, angle):\n",
    "    \"\"\"\n",
    "    1. Substract f_point\n",
    "    2. Caclualte x_p, y_p. \n",
    "    3. sum f_point\n",
    "    The idea was to apply a function to the whole dataframe, but we haven't yet done that optimized version\n",
    "    \"\"\"\n",
    "    X_copy = X\n",
    "    for i in range(0,len(X)):\n",
    "        X_copy.iat[i,0] = X.iloc[i,0] - f_point[0]\n",
    "        X_copy.iat[i,1] = X.iloc[i,1] - f_point[1]\n",
    "\n",
    "        x_p = np.cos(angle)*X_copy.iloc[i,0] - np.sin(angle)*X_copy.iloc[i,1]\n",
    "        y_p = np.sin(angle)*X_copy.iloc[i,0] + np.cos(angle)*X_copy.iloc[i,1]\n",
    "        \n",
    "        X_copy.iat[i,0] = x_p + f_point[0]\n",
    "        X_copy.iat[i,1] = y_p + f_point[1]\n",
    "    X = X_copy\n",
    "    return X\n",
    "\n",
    "   \n",
    "\n",
    "def get_clf():\n",
    "    \"\"\"\n",
    "    Return the classifier, so that we can test different classifiers and not only one\n",
    "    We don't need to change the instance everywhere, which outputs many errors due to the manual\n",
    "    change that it requires. \n",
    "\n",
    "    \"\"\"\n",
    "     \n",
    "#     C = 1000000000\n",
    "    return svm.SVC(kernel='linear', C=100000) \n",
    "#     return svm.NuSVC(kernel='linear', nu=0.0000001) \n",
    "\n",
    "def folding(X,Y,clf, plot = True):\n",
    "    \"\"\"\n",
    "    Gets the main support vector. \n",
    "    Divides the dataset into 2,based on the orthogonal line \n",
    "    to the plane and the main support vector. \n",
    "    Apply SVM on both sides, rotate the one with the greatest margin. \n",
    "    We need to remove the support vector, since it is repeated.\n",
    "    Set1, Set2: DF with their respective class. \n",
    "    prime_sv_index: To remove it later when folding\n",
    "    \"\"\"\n",
    "    # clf.support_ = indices of SVs\n",
    "    print(\"DEBUG: SVs 2 :\\n\", clf.support_vectors_)\n",
    "    prime_sv = get_support_vector(X,Y, clf.support_)\n",
    "    set1X, set2X, set1Y, set2Y, prime_sv_index = splitting(X, Y, clf, prime_sv)\n",
    "\n",
    "\n",
    "    print(\"DEBUG: After splitting: \")\n",
    "    print(\"DEBUG: Set1X: \") \n",
    "    display(set1X)\n",
    "    print(\"DEBUG: Set2X: \") \n",
    "    display(set2X)\n",
    "    clf_set1 = get_clf()\n",
    "    clf_set1.fit(set1X, set1Y)\n",
    "    margin1 = get_margin(clf_set1)\n",
    "    \n",
    "    clf_set2 = get_clf()\n",
    "    clf_set2.fit(set2X, set2Y)\n",
    "    margin2 = get_margin(clf_set2)\n",
    "    \n",
    "    f_point, angle = get_folding_point(clf_set1, clf_set2)\n",
    "    \n",
    "    if plot:\n",
    "        print(\"\\nSVM Set 1: LEFT\")\n",
    "        plot_SVM(clf_set1, np.array(set1X), np.array(set1Y),plot)\n",
    "        print(\"\\nSVM Set 2: RIGHT\")\n",
    "        plot_SVM(clf_set2, np.array(set2X), np.array(set2Y) ,plot)\n",
    "\n",
    "    # Fold points . Add them to the DF using the same indexes as before\n",
    "    if margin1 > margin2: \n",
    "        part_folded = \"left\"\n",
    "        print(\"Folding SET1\")\n",
    "        # Remove the primeSV. It's the index repeated in both sets\n",
    "        set1X = set1X.drop(prime_sv_index)\n",
    "        set1Y = set1Y.drop(prime_sv_index)\n",
    "\n",
    "        set1X_folded = folding_set(set1X, f_point, -angle)\n",
    "        X_folded = pd.concat([set1X_folded,set2X]).sort_index(inplace=False)\n",
    "        Y_folded = pd.concat([set1Y,set2Y]).sort_index(inplace=False)\n",
    "        \n",
    "    else:\n",
    "        part_folded = \"right\"\n",
    "        print(\"Folding SET2\")\n",
    "        set2X = set2X.drop(prime_sv_index)\n",
    "        set2Y = set2Y.drop(prime_sv_index)\n",
    "        \n",
    "        set2X_folded = folding_set(set2X, f_point, angle)\n",
    "        X_folded = pd.concat([set2X_folded,set1X]).sort_index(inplace=False)\n",
    "        Y_folded = pd.concat([set1Y,set2Y]).sort_index(inplace=False)\n",
    "\n",
    "      \n",
    "    print (\"DEBUG: After folding. \\n X Folded: \")\n",
    "    display(X_folded)\n",
    "    print(\"Y Folded: \")\n",
    "    display(Y_folded)\n",
    "\n",
    "    return angle, part_folded, X_folded, Y_folded, prime_sv, f_point\n",
    "\n",
    "def plot_points(x,y, should_plot):\n",
    "    if should_plot:\n",
    "        pdf = PdfPages('points' + str(time.clock()) + '.pdf')\n",
    "        \n",
    "        fig=figure(figsize=(6,4))\n",
    "        plt.scatter(x[:, 0], x[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "        plt.axis('tight')\n",
    "        plt.show()\n",
    "        pdf.savefig(fig) # note the format='pdf' argument!\n",
    "        pdf.close()\n",
    "        \n",
    "def remove_extra_sv(clf, X,Y):\n",
    "    \"\"\"\n",
    "    1. Remove the repeated SV\n",
    "    2. We remove it from the X,Y sets, and create a new clf. \n",
    "    \"\"\"\n",
    "    clf.support_vectors_ = np.around(clf.support_vectors_, decimals=6)\n",
    "#     X = dataset.iloc[:,:2]\n",
    "    unique_SVs, ind_SVs = np.unique(clf.support_vectors_, axis=0, return_index = True)\n",
    "    print(\"DEBUG: SVs after removing duplicates\")\n",
    "    print(unique_SVs)\n",
    "#     print(ind_SVs)\n",
    "    \n",
    "#     ind_extra_el =list()\n",
    "    tmp_set_ind = set(clf.support_[ind_SVs])\n",
    "    ind_extra_SVs = [x for x in clf.support_ if x not in tmp_set_ind]\n",
    "    \n",
    "    print(\"EXTRA SVs: index \",ind_extra_SVs )\n",
    "    print(\"EXTRA SVs: SVs \\n\", X.iloc[ind_extra_SVs] )\n",
    "    if ind_extra_SVs: # List not empty\n",
    "        X_tmp = X.drop(ind_extra_SVs)\n",
    "        Y_tmp = Y.drop(ind_extra_SVs)\n",
    "        clf = get_clf() \n",
    "        clf.fit(X_tmp, Y_tmp)\n",
    "        \n",
    "  \n",
    "        # We return the original information\n",
    "        \n",
    "#     if len(unique_SVs)>3:\n",
    "#         print(\"%% Remove extra SV. In progress %%\")\n",
    "#     else:\n",
    "#         clf.support_vectors_ = unique_SVs\n",
    "#         clf.support_ = clf.support_[ind_SVs]\n",
    "#         clf.dual_coef_ = clf.dual_coef_[0,ind_SVs]\n",
    "#         clf.dual_coef_ = clf.dual_coef_.reshape((1,-1))\n",
    "    \n",
    "\n",
    "#     SV0 = clf.support_vectors_[dataset['class'][clf.support_]==0]\n",
    "#     SV1 = clf.support_vectors_[dataset['class'][clf.support_]==1]\n",
    "#     clf.support_vectors_ = SV0[0:2]+SV1[0:1]\n",
    "#     clf.support\n",
    "\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset(filename):\n",
    "    dataset = pd.read_csv('../../datasets/'+filename)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3 : Number of dimensions. \n",
    "def rotate_3SV(X,clf):\n",
    "    dim = 3\n",
    "    n_sv = len(clf.support_vectors_)\n",
    "    m = n_sv - 1\n",
    "    w = np.zeros((m,dim))\n",
    "    W = np.zeros((m,dim))\n",
    "    for i in range(1,n_sv):\n",
    "        w[i-1] = clf.support_vectors_[i] - clf.support_vectors_[0]\n",
    "        \n",
    "    # Not sure why we need this, but I am following the formula\n",
    "    W = w\n",
    "    \n",
    "    # Gram-Schmidt. \n",
    "    fm = np.zeros((m,dim))\n",
    "    fm[0] = W[0]\n",
    "    fm[1] = W[1] - (np.dot(fm[0],W[1]) / np.dot(fm[0], fm[0]) * fm[0])\n",
    "    \n",
    "    # f3. We need to obtain f3, as an orthogonal vector to fm1, fm2. Then we normalize all 3 to become fn. \n",
    "    # With H eq. z always set to 1 atm.\n",
    "    f3 = [0,0,0]\n",
    "    x, y, z = symbols('x y z')\n",
    "#     print(\"SOLVER: \")\n",
    "    eq = (solve([Eq(fm[0][0]*x + fm[0][1]*y + fm[0][2]*z, 0), \n",
    "           Eq(fm[1][0]*x + fm[1][1]*y + fm[1][2]*z, 0),\n",
    "           Eq(z,1)],[x, y,z]))\n",
    "    \n",
    "    f3[0] = eq[x]\n",
    "    f3[1] = eq[y]\n",
    "    f3[2] = eq[z]\n",
    "    \n",
    "    # Orthonormal: fn. I need one more dimension. n=number of dimensions. n = 3\n",
    "    # Q? We need to find fn[2] before normalizing?\n",
    "    fn = np.zeros((dim,dim))\n",
    "    fn[0] =  fm[0] / np.sqrt(math.pow(fm[0][0],2) + math.pow(fm[0][1],2) + math.pow(fm[0][2],2))    \n",
    "    fn[1] =  fm[1] / np.sqrt(math.pow(fm[1][0],2) + math.pow(fm[1][1],2) + math.pow(fm[1][2],2))\n",
    "    fn[2] =  f3 / np.sqrt(math.pow(f3[0],2) + math.pow(f3[1],2) + math.pow(f3[2],2))\n",
    "#     fn[2] =  f3 / np.sqrt(math.pow(f3[0],2) + math.pow(f3[2],2) + math.pow(f3[2],2))\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"fm: \", fm)\n",
    "    print(\"fn NORMALIZED: \", fn)\n",
    "    \n",
    "    # 4. Form a n   n-matrix P where f1 ; :::; fn are column vectors. \n",
    "    # This gives the rotation matrix R = P T (transpose). So basically the same as having fn as row vectors\n",
    "    # that is exactly what we have. \n",
    "    \n",
    "    rot_matx = fn \n",
    "    print(\"ROTATION MATRIX: \\n\", rot_matx)\n",
    "    # 5. Move the origin to v1; i.e. add  v1 to all points.\n",
    "    X = X - clf.support_vectors_[0]\n",
    "    print(\"DEBUG: Points moved based on \", clf.support_vectors_[0])\n",
    "    print(X)\n",
    "    X_projected = pd.DataFrame(columns=X.columns)\n",
    "    for index, row in X.iterrows():\n",
    "        newpoint = np.dot(rot_matx,row.transpose())\n",
    "        X_projected.loc[index] = newpoint\n",
    "    \n",
    "    return X_projected\n",
    "\n",
    "    \n",
    "def rotate_4SV(X,clf,dataset):\n",
    "    # 1. Get indexes of class 0, and class 1\n",
    "    SV0 = clf.support_vectors_[dataset['class'][clf.support_]==0]\n",
    "    SV1 = clf.support_vectors_[dataset['class'][clf.support_]==1]\n",
    "    print(\"DEBUG: SV0 \", SV0 )\n",
    "    print(\"DEBUG: SV1 \", SV1 )     \n",
    "\n",
    "    #2. If we have 3 elements of class 0\n",
    "    # or class 1 , we calculate the distances between each other, and get the minimum one\n",
    "    if len(SV0)>2 or len(SV1)>2:\n",
    "        if len(SV0)>2:\n",
    "            SVi = SV0\n",
    "        else:\n",
    "            SVi = SV1\n",
    "        d01 = abs(np.linalg.norm(SVi[0]-SVi[1])) \n",
    "        d02 = abs(np.linalg.norm(SVi[0]-SVi[2])) \n",
    "        d12 = abs(np.linalg.norm(SVi[1]-SVi[2])) \n",
    "        dist = [d01,d02,d12]\n",
    "        min_index = dist.index(min(dist))\n",
    "        if min_index == 0: #d01 is the one with the minumum distances\n",
    "            v = SVi[0]\n",
    "            u = SVi[1]\n",
    "        elif min_index == 1:\n",
    "            v = SVi[0]\n",
    "            u = SVi[2]\n",
    "        else: \n",
    "            v = SVi[1]\n",
    "            u = SVi[2]\n",
    "    else:\n",
    "        d1 = abs(np.linalg.norm(SV0[0]-SV0[1])) \n",
    "        d2 = abs(np.linalg.norm(SV1[0]-SV1[1])) \n",
    "        v = SV0[0]\n",
    "        u = SV0[1]\n",
    "        if d1 > d2:\n",
    "            v = SV1[0]\n",
    "            u = SV1[1]\n",
    "\n",
    "    \n",
    "#     # Calculating distance. Need to check all the SV, check the shortest distance for each pair. \n",
    "#     d1 = abs(np.linalg.norm(clf.support_vectors_[0]-clf.support_vectors_[1])) \n",
    "#     d2 = abs(np.linalg.norm(clf.support_vectors_[2]-clf.support_vectors_[3]))\n",
    "\n",
    "#     v = clf.support_vectors_[0]\n",
    "#     u = clf.support_vectors_[1]\n",
    "    \n",
    "#     if d1 > d2:\n",
    "#         v = clf.support_vectors_[2]\n",
    "#         u = clf.support_vectors_[3]\n",
    "  \n",
    "    print(\"v: \", v, \" u: \", u)\n",
    "    w = v - u\n",
    "    \n",
    "    print(\"w: \", w)\n",
    "    W = np.linalg.norm(w)\n",
    "    print(\"W: \", W)\n",
    "    W_12 = np.linalg.norm(w[:2])\n",
    "    print(\"W12: \", W_12)\n",
    "\n",
    "    cosTheta = (w[2])/W\n",
    "    sinTheta = W_12/W\n",
    "\n",
    "    R = [[ ((w[2]/W) + (w[1]**2 * (1-(w[2]/W))/W_12**2)) , -w[0]*w[1]*(1-(w[2]/W))/W_12**2, -w[0]/W],\n",
    "         [-w[0]*w[1] * ((1-(w[2]/W))/W_12**2), w[2]/W + (w[0]**2*(1-(w[2]/W))/W_12**2), -w[1]/W], \n",
    "         [w[0]/W , w[1]/W, w[2]/W]]\n",
    "    \n",
    "    print(\"ROTATION MATRIX:\\n \", R)\n",
    "    X_rotated = pd.DataFrame(columns=X.columns)\n",
    "    for index, row in X.iterrows():\n",
    "        newpoint = np.dot(R,row.transpose())\n",
    "        X_rotated.loc[index] = newpoint\n",
    "    \n",
    "    return X_rotated\n",
    "\n",
    "\n",
    "def rotate_points(dataset):\n",
    "    \"\"\"\n",
    "    Projecting the points from 3D to 2D, so that they are orthogonal to the Z axis.\n",
    "    Håkan Lennerstad's formulas\n",
    "    \n",
    "    1. Apply SVM on dataset\n",
    "    2. Get pair of support vectors\n",
    "    3. Choose the pair with the minumum distance \n",
    "    \"\"\"\n",
    "    \n",
    "    X = dataset.iloc[:,:3]\n",
    "    Y = dataset['class']\n",
    "    clf = get_clf()\n",
    "    clf.fit(X, Y)\n",
    "    \n",
    "    print(\"Rotation\")\n",
    "    print(\"Number of SVs\", len(clf.support_vectors_), \"\\nSV index: \", clf.support_)\n",
    "    print(\"SVs\\n\", clf.support_vectors_)\n",
    "\n",
    "    \n",
    "    if len(clf.support_vectors_) == 3:\n",
    "        X_rotated = rotate_3SV(X,clf)\n",
    "#         print(\"3 SVs\")\n",
    "    else:\n",
    "        X_rotated = rotate_4SV(X,clf,dataset)\n",
    "#         print(\"4 SVs\")\n",
    "        # If we have more than 4: We take 2 from each class. \n",
    "        \n",
    "    print (\"X initial points:\" )\n",
    "    display(X)\n",
    "    print (\"\\nX Rotated points:\")\n",
    "    display(X_rotated)\n",
    "    # DEBUGGING\n",
    "    clf = get_clf()\n",
    "    clf.fit(X, Y)\n",
    "    print (\"DEBUG: SVs of initial X:\\n \", clf.support_vectors_)\n",
    "    clf = get_clf()\n",
    "    clf.fit(X_rotated, Y)\n",
    "    print (\"DEBUG: SVs of rotated X before removing Z:\\n \", clf.support_vectors_)\n",
    "\n",
    "    Z = X_rotated.iloc[:,2]\n",
    "#     print \"\\nZ component: \\n\", Z\n",
    "    X_rotated = X_rotated.iloc[:,0:2]\n",
    "    print (\"\\nX Rotated points after removing Z :\" )\n",
    "    display(X_rotated)\n",
    "    clf = get_clf()\n",
    "    clf.fit(X_rotated, Y)\n",
    "    print (\"DEBUG: SVS of rotated X after removing Z:\\n \", clf.support_vectors_)\n",
    "\n",
    "\n",
    "    return X_rotated, Z\n",
    "\n",
    "def get_nSV_3D(dataset):\n",
    "    X = dataset.iloc[:,:3]\n",
    "    Y = dataset['class']\n",
    "    clf = get_clf()\n",
    "    clf.fit(X, Y)\n",
    "    return len(clf.support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulation: Training. \n",
    "\n",
    "def training(dataset, iterations):\n",
    "    \"\"\"\n",
    "    Training SVM on dataset\n",
    "    When removing the extra SV, we pass a new dataset without the extra SV to a new clf, that is the output\n",
    "    of the remove_extra_sv function. \n",
    "    X and Y remain the same\n",
    "    \"\"\"\n",
    "    print(\"\\nStarting training\")\n",
    "    # Dictionary that saves the information of every rotation\n",
    "    folding_info = dict()\n",
    "    \n",
    "    # Data\n",
    "    angle, part_folded, x_folded, y_folded, prime_sv, f_point = None, None, None, None, None, None\n",
    "    should_plot = True\n",
    "    Y = dataset['class']\n",
    "    \n",
    "    for i in range(0,iterations): \n",
    "        print(\"ITERATION \", i+1)\n",
    "        # 0. Check N SVs:\n",
    "        if get_nSV_3D(dataset)<3:\n",
    "            print(\"Training is over. Number of SVs is: \",get_nSV_3D(dataset))\n",
    "            break\n",
    "        \n",
    "        # 1. Rotation: Translating 3D to 2D\n",
    "        X_rotated, Z = rotate_points(dataset)\n",
    "        X = X_rotated\n",
    "        \n",
    "        # 2. SVM, margin and plot of the initial points. \n",
    "        clf = get_clf() \n",
    "        clf.fit(X, Y)\n",
    "        margin = get_margin(clf)\n",
    "        print(\"Initial Plot\")\n",
    "        plot_SVM(clf,np.array(X), np.array(Y), should_plot)\n",
    "\n",
    "\n",
    "        # Remove extra support vectors only when needed. That is then the shape of the SVs is =!\n",
    "        # from [2,1] or [1,2]\n",
    "        if (clf.n_support_[0]==1 and clf.n_support_[1]==2) or (clf.n_support_[0]==2 and clf.n_support_[1]==1):\n",
    "            print (\"Training: No need to remove extra SVs\")\n",
    "        else:\n",
    "            print(\"Training: Removing extra SVs\")\n",
    "            print(\"DEBUG: SV INDX before removing extra:\\n\", clf.support_)\n",
    "            clf = remove_extra_sv(clf,X,Y)\n",
    "            print(\"Plot after removing extra SVs\")\n",
    "            plot_SVM(clf, np.array(X), np.array(Y), should_plot)\n",
    "            print(\"DEBUG: SV INDX after removing extra:\\n\", clf.support_)\n",
    "\n",
    "        if i==0:\n",
    "            print(\"\\nInitial SVM. No folding yet.  Initial Margin: {:f}\".format(margin))\n",
    "        else:\n",
    "            print(\"Folding number: \", i+1)\n",
    "            print(\"DEBUG: SVs before folding, after removing extra SV :\\n\", clf.support_vectors_)\n",
    "            print(\"DEBUG: SV INDX before folding, after removing extra SV :\\n\", clf.support_)\n",
    "\n",
    "\n",
    "        # 3. Folding. \n",
    "        angle, part_folded, X_folded, Y_folded, prime_sv, f_point = folding(X, Y, clf)\n",
    "\n",
    "        folding_info[str(i)] = {'margin': margin, 'clf': clf, 'angle': angle, \n",
    "                           'part':part_folded, 'X_folded': X_folded, \n",
    "                           'Y_folded': Y_folded, 'prime_support_vector': prime_sv,\n",
    "                           'f_point': f_point}\n",
    "        \n",
    "#         print(\"Folding point: \", f_point)\n",
    "        # 4. SVM on the folded points, to check the margin increase. Plot it\n",
    "        clf = get_clf() \n",
    "        clf.fit(X_folded, Y_folded)\n",
    "        margin = get_margin(clf)\n",
    "        print(\"Folding {:d} . Folding the {:s}. New margin: {:f}\".format(i+1,part_folded, margin))\n",
    "        plot_SVM(clf,np.array(X_folded), np.array(Y_folded), should_plot)\n",
    "\n",
    "\n",
    "        # 5. Add the Z component. \n",
    "        dataset_after_folding = pd.concat([X_folded, Z,  Y_folded], axis=1)\n",
    "        print(\"DATASET after folding. Adding Z component\")\n",
    "        display(dataset_after_folding)\n",
    "        dataset=dataset_after_folding\n",
    "        Y = dataset_after_folding['class']\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulation: Testing\n",
    "# Need to do the same rotations that we did for training, and keep track of it. \n",
    "\n",
    "\n",
    "def testing(dataset):\n",
    "    print(\"Testing: Not doing anything atm\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "####             MAIN               ####\n",
    "#### April 2018.                    ####\n",
    "#### 3D case for hyperplane folding ####\n",
    "#### 1. Projecting                  ####\n",
    "#### 2. 2D case                     ####\n",
    "########################################\n",
    "\n",
    "\n",
    "# Import necessary packages\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from random import randint\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import time\n",
    "from pylab import *\n",
    "from sympy import *\n",
    "from IPython.display import display, HTML\n",
    "from collections import Counter\n",
    "\n",
    "def main():\n",
    "    iterations=3\n",
    "    \n",
    "    # Dataset\n",
    "    dataset = load_dataset('iris.csv')\n",
    "    Y = dataset['class']\n",
    "    print(\"Initial Dataset \")\n",
    "    display(dataset)\n",
    "\n",
    "    # Training \n",
    "    training(dataset, iterations)\n",
    "\n",
    "    # Testing \n",
    "    testing(dataset)\n",
    "\n",
    "    \n",
    "if __name__ =='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
